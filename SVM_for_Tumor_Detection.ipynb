{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nooralotibi/API/blob/main/SVM_for_Tumor_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhwdkcJr5YZS"
      },
      "source": [
        "# **Support Vector Machine for Tumor Detection**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Objective:** In this exercise, we will train a Machine Learning Model using Support Vector Machine algorithm from the scikit library, to implement a classification model on a breast cancer dataset.\n",
        "\n",
        "We will be classifying if a tumor is (2) Benign or (4) Malignant from these inputs:\n",
        "\n",
        "*   Clump Thickness (1-10)\n",
        "*   Uniformity of Cell Size (1-10)\n",
        "*   Uniformity of Cell Shape (1-10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2igl0cIT61t-"
      },
      "source": [
        "# Importing Needed Libraries:\n",
        "\n",
        "* numpy: for scientific computing\n",
        "* matplotlib: for plotting and visualization\n",
        "* pandas: for data reading and manipulation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHL2azdc06yo"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbvcpyvJ7_XV"
      },
      "source": [
        "# Importing the Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The Data is currently stored in a CSV file named **breast-cancer-wisconsin.csv**"
      ],
      "metadata": {
        "id": "X-v3sXKRlORH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tua4-9c9Iq4"
      },
      "source": [
        " #Read the Data file\n",
        "\n",
        " #Prints the first 5 rows of the data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC6bVBdP_qzz"
      },
      "source": [
        "# Number of Rows and Columns:\n",
        "Let's dig and see the number of rows and columns in our data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMTzHQsw9bkd"
      },
      "source": [
        "n_rows = data.shape[0]\n",
        "n_columns = data.shape[1]\n",
        "print('There are ' + str(n_rows) + ' rows and ' + str(n_columns) + ' columns.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBkei2GjANAc"
      },
      "source": [
        "# Data Preprocessing:\n",
        "\n",
        "Data preprocessing involves dividing the data into features/attributes and labels, and then we will move to divide them into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A4BSx0PAdle"
      },
      "source": [
        "#all the columns except the ID and Class columns are being stored as input\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbL-tQP8jIn5"
      },
      "source": [
        "Now we will split our data between training and testing by using the scikit learn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJiQU6-wBfMP"
      },
      "source": [
        "#Scikit-Learn Library contains the train_test_split method that allows the division of data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#20% of the data is assigned for testing, and the rest for training\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-9N8eF4CZX4"
      },
      "source": [
        "# Training the Algorithm: Linear SVM\n",
        "To train the SVM on the training data, we will use scikit-learn's svm library. This class takes the kernel type as parameter, and as a start we will use a 'linear' kernel for simplicity to see if we can seperate the data linearly, keeping non-linear kernels for the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8g6XzSPjxIa"
      },
      "source": [
        "SVC stands for Support Vector Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TuUtVpT_-XJ"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9mS69qtD5FD"
      },
      "source": [
        "# Predictions:\n",
        "In order to make predictions, we will use \"predict\" from the svc class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgwExA-3DyQe"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STezhhXCESE-"
      },
      "source": [
        "# Evaluating our Algorithm\n",
        "We will be using an accuracy based metric to evaluate our algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGpUG-diERCk"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print (\"Our model predicts the test set with \" + str( 100*accuracy_score(y_test,y_pred) ) +\"% accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA4r5MpcIXOf"
      },
      "source": [
        "# Plotting the SVM:\n",
        "We will be using the matplotlib.pyplot library to plot the results of our predictions on the test set with the decision boundary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS9PGq-ZkMSQ"
      },
      "source": [
        "The form of the decision boundary in an SVM Classification would be of the form a0 + a1 x + a2 y +a3 z = 0\n",
        "\n",
        "Given that the 3 features x, y, and z are respectively the \"Clump Thickness\" \"Uniformity of Cell Size\" and the \"Uniformity of Cell Shape\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgZEWiRDlLKv"
      },
      "source": [
        "To draw this equation, we will change its form to be: z = a x + by + c\n",
        "<br>Where:\n",
        "\n",
        "*   a = -a1/a3\n",
        "*   b = -a2/a3\n",
        "*   c = -a0/a3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foiHnlw5kxtb"
      },
      "source": [
        "#Capture the coefficients of the features x, and y (which are a1, and a2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Get the intercept (which is a0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "a0 = intercept\n",
        "a1 = coefficients[0] # The 1st feature : Clump Thickness\n",
        "a2 = coefficients[1] # The 2nd feature : Uniformity of Cell Size\n",
        "a3 = coefficients[2] # The 3rd feature : Uniformity of Cell Shape\n",
        "\n",
        "a = -a1/a3\n",
        "b = -a2/a3\n",
        "c = -a0/a3\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(projection='3d') #note: we're plotting in a 3D space\n",
        "\n",
        "#Plot the dataPoints\n",
        "data_x = np.array(x_test)[:,0] # Clump Thickness\n",
        "data_y = np.array(x_test)[:,1] # Uniformity of Cell Size\n",
        "data_z = np.array(x_test)[:,2] # Uniformity of Cell Shape\n",
        "ax.scatter3D(data_x, data_y, data_z, c=y_pred, cmap=plt.cm.coolwarm)\n",
        "\n",
        "#Now we will plot z = ax + by + c (the separator / decision boundary - aka the model - learned by the SVC algorithm)\n",
        "x_min, x_max = data_x.min() - 1, data_x.max() + 1\n",
        "y_min, y_max = data_y.min() - 1, data_y.max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, .2), np.arange(y_min, y_max, .2))\n",
        "zz = a*xx + b*yy + c\n",
        "\n",
        "ax.plot_surface(xx, yy, zz, rstride=1, cstride=1, cmap='viridis', edgecolor='none' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acy6cFNARk6X"
      },
      "source": [
        "As seen above, the data is clearly linearly seperable."
      ]
    }
  ]
}